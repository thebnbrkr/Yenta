import asyncio
import typer
import yaml
import tempfile
import sys
from pathlib import Path
from typing import Optional, Dict, Any
from rich.console import Console
from rich.table import Table
from rich import print as rprint

from agora.telemetry import AuditLogger
from yenta.flow import MCPTestFlow
from yenta.workflow_flow import MCPWorkflowFlow
#from yenta.registry import JsonRegistry
from yenta.registry import get_shared_registry

app = typer.Typer(
    name="yenta",
    help=" Yenta - MCP Testing & Workflow Orchestration Framework",
    add_completion=False
)
console = Console()


async def _run_flow(spec_file: Path, session_id: Optional[str] = None, override_mode: Optional[dict] = None):
    """Internal helper to run the test flow with optional mode overrides"""
    
    # Load and potentially modify the spec
    if override_mode:
        with open(spec_file) as f:
            spec_data = yaml.safe_load(f)
        
        # Apply overrides
        spec_data.update(override_mode)
        
        # Save to temp file
        with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as tmp:
            yaml.dump(spec_data, tmp)
            tmp_path = tmp.name
        
        actual_spec_file = Path(tmp_path)
    else:
        actual_spec_file = spec_file
        tmp_path = None
    
    try:
        logger = AuditLogger(session_id=session_id or f"yenta-{spec_file.stem}")
        flow = MCPTestFlow(logger)
        
        result = await flow.run_async({"spec_file": str(actual_spec_file)})
        
        # Print summary
        rprint("\n" + "=" * 70)
        rprint("üìä [bold cyan]AUDIT SUMMARY[/bold cyan]")
        rprint("=" * 70)
        summary = logger.get_summary()
        rprint(f"Session ID: {summary['session_id']}")
        rprint(f"Total Events: {summary['total_events']}")
        rprint(f"Duration: {summary.get('duration_seconds', 0):.2f}s")
        
        rprint("\n[bold]Event Breakdown:[/bold]")
        for event, count in summary['event_counts'].items():
            rprint(f"  {event}: {count}")
        
        return result
    finally:
        # Cleanup temp file if created
        if tmp_path:
            Path(tmp_path).unlink(missing_ok=True)


async def _run_workflow(
    workflow_file: Path, 
    session_id: Optional[str] = None,
    input_data: Optional[Dict[str, Any]] = None,
    debug: bool = False
):
    """Internal helper to run workflow orchestration"""
    
    if not workflow_file.exists():
        rprint(f"[red]‚ùå Workflow file not found: {workflow_file}[/red]")
        raise typer.Exit(1)
    
    # Load workflow YAML
    with open(workflow_file) as f:
        spec = yaml.safe_load(f)
    
    # Extract required fields
    workflow_name = spec.get("workflow_name", workflow_file.stem)
    server_path = spec.get("mcp_server")
    workflow_lines = spec.get("workflow", [])
    initial_input = spec.get("initial_input", {})
    custom_nodes_file = spec.get("custom_nodes")  # ‚ú® FIX 1: Extract custom_nodes
    
    # Merge CLI input with YAML input
    if input_data:
        initial_input.update(input_data)
    
    if not server_path:
        rprint("[red]‚ùå Missing 'mcp_server' in workflow YAML[/red]")
        raise typer.Exit(1)
    
    if not workflow_lines:
        rprint("[red]‚ùå Missing 'workflow' in workflow YAML[/red]")
        raise typer.Exit(1)
    
    # Create logger and flow
    logger = AuditLogger(session_id=session_id or f"workflow-{workflow_name}")
    
    try:
        flow = MCPWorkflowFlow(
            workflow_name=workflow_name,
            server_path=server_path,
            workflow_spec=workflow_lines,
            logger=logger,
            initial_input=initial_input,
            custom_nodes_file=custom_nodes_file  # ‚ú® FIX 1: Pass custom_nodes
        )
        
        # Run workflow
        rprint(f"\nüîÑ [bold cyan]Running workflow:[/bold cyan] {workflow_name}\n")
        result = await flow.run_async()
        
        # Print results
        rprint("\n" + "=" * 70)
        rprint("‚úÖ [bold green]WORKFLOW COMPLETED[/bold green]")
        rprint("=" * 70)
        
        # Show outputs from each node
        import json
        rprint("\n[bold]Node Outputs:[/bold]")
        for key, value in result.items():
            if key.endswith("_output"):
                node_name = key.replace("_output", "")
                rprint(f"\n[cyan]{node_name}:[/cyan]")
                
                # Handle FastMCP response objects
                if hasattr(value, '__dict__'):
                    rprint(f"  Type: {type(value).__name__}")
                    if hasattr(value, 'content') and value.content:
                        rprint(f"  Content: {str(value.content)[:500]}")
                    elif hasattr(value, 'model_dump'):
                        try:
                            rprint(f"  {json.dumps(value.model_dump(), indent=2, default=str)[:500]}")
                        except:
                            rprint(f"  {str(value)[:500]}")
                    else:
                        rprint(f"  {str(value)[:500]}")
                else:
                    try:
                        rprint(f"  {json.dumps(value, indent=2, default=str)[:500]}")
                    except:
                        rprint(f"  {str(value)[:500]}")
        
        # Print telemetry summary
        rprint("\n" + "=" * 70)
        rprint("üìä [bold cyan]TELEMETRY SUMMARY[/bold cyan]")
        rprint("=" * 70)
        summary = logger.get_summary()
        rprint(f"Session ID: {summary['session_id']}")
        rprint(f"Total Events: {summary['total_events']}")
        rprint(f"Duration: {summary.get('duration_seconds', 0):.2f}s")
        
        rprint("\n[bold]Event Breakdown:[/bold]")
        for event, count in summary['event_counts'].items():
            rprint(f"  {event}: {count}")
        
        return result
        
    except Exception as e:
        # ‚ú® FIX 3: Better error messages
        rprint(f"\n[red]‚ùå Workflow failed: {e}[/red]")
        
        if debug or "--debug" in sys.argv:
            import traceback
            rprint("\n[dim]Full traceback:[/dim]")
            traceback.print_exc()
        else:
            rprint("[dim]Run with --debug for full traceback[/dim]")
        
        raise typer.Exit(1)


@app.command()
def run(
    spec_file: str = typer.Argument(..., help="YAML spec file to run"),
    session_id: Optional[str] = typer.Option(None, "--session", "-s", help="Custom session ID"),
    record: bool = typer.Option(False, "--record", "-r", help="Enable recording mode"),
    replay: bool = typer.Option(False, "--replay", "-p", help="Enable replay mode (use mocks)")
):
    """üöÄ Run MCP tests from a YAML spec"""
    
    spec_path = Path(spec_file)
    if not spec_path.exists():
        rprint(f"[red]‚ùå Spec file not found: {spec_file}[/red]")
        raise typer.Exit(1)
    
    # Determine override mode
    override = None
    if record and replay:
        rprint("[yellow]‚ö†Ô∏è  Both --record and --replay specified. Using --record.[/yellow]")
        override = {"use_mocks": False, "record_mocks": True}
    elif record:
        override = {"use_mocks": False, "record_mocks": True}
    elif replay:
        override = {"use_mocks": True, "record_mocks": False}
    
    mode = "üé¨ RECORD" if record else ("üîÑ REPLAY" if replay else "‚ñ∂Ô∏è  RUN")
    rprint(f"\n{mode}: [bold]{spec_file}[/bold]\n")
    
    try:
        asyncio.run(_run_flow(spec_path, session_id, override))
        if record:
            rprint(f"\n[green]‚úÖ Recordings saved to data/mocks/[/green]")
    except Exception as e:
        rprint(f"[red]‚ùå Test run failed: {e}[/red]")
        raise typer.Exit(1)


@app.command()
def workflow(
    workflow_file: str = typer.Argument(..., help="Workflow YAML file to run"),
    session_id: Optional[str] = typer.Option(None, "--session", "-s", help="Custom session ID"),
    input: Optional[str] = typer.Option(None, "--input", "-i", help="Initial input as JSON string"),
    debug: bool = typer.Option(False, "--debug", "-d", help="Show full error tracebacks")
):
    """üîó Run MCP workflow orchestration"""
    
    workflow_path = Path(workflow_file)
    
    # Parse input JSON if provided
    input_data = None
    if input:
        import json
        try:
            input_data = json.loads(input)
        except json.JSONDecodeError as e:
            rprint(f"[red]‚ùå Invalid JSON input: {e}[/red]")
            raise typer.Exit(1)
    
    try:
        asyncio.run(_run_workflow(workflow_path, session_id, input_data, debug))
    except Exception as e:
        if not isinstance(e, typer.Exit):
            rprint(f"[red]‚ùå Workflow execution failed: {e}[/red]")
            raise typer.Exit(1)


@app.command()
def record(
    spec_file: str = typer.Argument(..., help="YAML spec file to record"),
    session_id: Optional[str] = typer.Option(None, "--session", "-s", help="Custom session ID")
):
    """üìù Record MCP calls for future replay"""
    
    rprint(f"üìù [bold red]Recording[/bold red]: {spec_file}\n")
    
    spec_path = Path(spec_file)
    if not spec_path.exists():
        rprint(f"[red]‚ùå Spec file not found: {spec_file}[/red]")
        raise typer.Exit(1)
    
    # Override: use_mocks=false, record_mocks=true
    override = {"use_mocks": False, "record_mocks": True}
    
    try:
        asyncio.run(_run_flow(spec_path, session_id, override))
        rprint(f"\n[green]‚úÖ Recordings saved to data/mocks/[/green]")
    except Exception as e:
        rprint(f"[red]‚ùå Recording failed: {e}[/red]")
        raise typer.Exit(1)


@app.command()
def replay(
    spec_file: str = typer.Argument(..., help="YAML spec file to replay"),
    session_id: Optional[str] = typer.Option(None, "--session", "-s", help="Custom session ID")
):
    """üîÑ Replay tests using recorded mocks"""
    
    rprint(f"üîÑ [bold blue]Replaying[/bold blue]: {spec_file}\n")
    
    spec_path = Path(spec_file)
    if not spec_path.exists():
        rprint(f"[red]‚ùå Spec file not found: {spec_file}[/red]")
        raise typer.Exit(1)
    
    registry = get_shared_registry()
    stats = registry.get_stats()
    if stats["total_mocks"] == 0:
        rprint("[yellow]‚ö†Ô∏è  No mocks found. Run 'yenta record' first.[/yellow]")
    
    # Override: use_mocks=true, record_mocks=false
    override = {"use_mocks": True, "record_mocks": False}
    
    try:
        asyncio.run(_run_flow(spec_path, session_id, override))
    except Exception as e:
        rprint(f"[red]‚ùå Replay failed: {e}[/red]")
        raise typer.Exit(1)


@app.command()
def status():
    """üìä Show registry status"""
    
    registry = get_shared_registry()
    stats = registry.get_stats()
    
    table = Table(title="üé≠ Yenta Registry Status")
    table.add_column("Metric", style="cyan")
    table.add_column("Value", style="green")
    
    table.add_row("Data Directory", stats["data_dir"])
    table.add_row("Total Mocks", str(stats["total_mocks"]))
    table.add_row("  ‚îú‚îÄ Tools", str(stats["tools"]))
    table.add_row("  ‚îú‚îÄ Resources", str(stats["resources"]))
    table.add_row("  ‚îî‚îÄ Prompts", str(stats["prompts"]))
    table.add_row("Total Runs", str(stats["total_runs"]))
    
    if stats["total_mocks"] > 0:
        table.add_row("Status", "‚úÖ Ready for replay")
    else:
        table.add_row("Status", "No recordings yet")
    
    console.print(table)
    
    # Show recorded tools
    if stats["total_mocks"] > 0:
        rprint("\n[bold]Recorded Tools:[/bold]")
        mocks = registry.list_mocks()
        tools = set(m.name for m in mocks)
        for tool in sorted(tools):
            rprint(f"  ‚Ä¢ {tool}")


@app.command()
def history(
    limit: int = typer.Option(10, "--limit", "-n", help="Number of runs to show")
):
    """üìú Show test run history"""
    
    registry = get_shared_registry()
    runs = registry.list_runs(limit=limit)
    
    if not runs:
        rprint("[yellow]No test runs found[/yellow]")
        return
    
    table = Table(title=f"üìú Recent Test Runs (last {len(runs)})")
    table.add_column("Timestamp", style="cyan")
    table.add_column("Spec", style="green")
    table.add_column("Status", style="yellow")
    table.add_column("Duration", style="magenta")
    table.add_column("Pass/Total", style="blue")
    
    for run in runs:
        passed = sum(1 for r in run.results if r.status == "PASS")
        total = len(run.results)
        status_icon = "‚úÖ" if run.status == "completed" else "‚ùå"
        
        table.add_row(
            run.timestamp.strftime("%Y-%m-%d %H:%M:%S"),
            run.spec_name,
            f"{status_icon} {run.status}",
            f"{run.duration_ms:.0f}ms",
            f"{passed}/{total}"
        )
    
    console.print(table)


@app.command()
def clear(
    category: Optional[str] = typer.Option(None, "--category", "-c", help="Clear specific category (tools/resources/prompts)"),
    confirm: bool = typer.Option(False, "--yes", "-y", help="Skip confirmation"),
):
    """üßπ Clear recorded mocks"""
    
    registry = get_shared_registry()
    stats = registry.get_stats()
    
    if stats["total_mocks"] == 0:
        rprint("[yellow]‚ÑπÔ∏è  No mocks found. Nothing to clear.[/yellow]")
        return
    
    if category:
        count = stats.get(category, 0)
        if count == 0:
            rprint(f"[yellow]‚ÑπÔ∏è  No {category} mocks found.[/yellow]")
            return
        if not confirm:
            rprint(f"‚ö†Ô∏è  This will delete [bold]{count}[/bold] {category} mock(s).")
            confirm = typer.confirm("Are you sure?")
    else:
        if not confirm:
            rprint(f"‚ö†Ô∏è  This will delete [bold]{stats['total_mocks']}[/bold] total mock(s).")
            confirm = typer.confirm("Are you sure?")
    
    if confirm:
        registry.clear_mocks(category)
        rprint("[green]‚úÖ Mocks cleared successfully[/green]")
    else:
        rprint("[yellow]Cancelled[/yellow]")


@app.command()
def inspect(
    tool: Optional[str] = typer.Option(None, "--tool", "-t", help="Filter by tool name"),
    category: Optional[str] = typer.Option(None, "--category", "-c", help="Filter by category (tools/resources/prompts)")
):
    """üîç Inspect recorded mocks"""
    
    registry = get_shared_registry()
    mocks = registry.list_mocks(category=category)
    
    if not mocks:
        rprint("[yellow]‚ùå No mocks found[/yellow]")
        return
    
    # Filter by tool if specified
    if tool:
        mocks = [m for m in mocks if m.name == tool]
        if not mocks:
            rprint(f"[yellow]‚ùå No mocks found for tool '{tool}'[/yellow]")
            return
    
    import json
    
    rprint(f"\n[bold cyan]üìã Recorded Mocks ({len(mocks)} total)[/bold cyan]\n")
    
    for i, mock in enumerate(mocks, 1):
        rprint(f"[bold]{i}. {mock.name}[/bold] [dim]({mock.category})[/dim]")
        rprint(f"   Args: {mock.arguments}")
        rprint(f"   Response: {json.dumps(mock.response, indent=2)[:200]}...")
        rprint(f"   Recorded: {mock.recorded_at.strftime('%Y-%m-%d %H:%M:%S')}")
        rprint()


if __name__ == "__main__":
    app()
